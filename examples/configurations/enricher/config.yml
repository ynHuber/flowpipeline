---
###############################################################################
# Consume flow messages from a pre-existing Kafka cluster containing
# protobuf-encoded flows in a topic. This topic can be generated by another
# pipeline, or by goflow itself.
- segment: kafkaconsumer
  config:
    server: kafka01.example.com:9093
    topic: flow-messages-plain
    group: enricher-group-1
    user: enricher
    pass: $KAFKA_SASL_PASS

###############################################################################
# Filter flows for relevancy before proceeding to enrich them.
- segment: flowfilter
  config:
    filter:  # optionally filter for relevancy here

###############################################################################
# This tags all flows with the information whether their source or destination
# address is the remote address, thus also allowing the inference which one
# will be the local one.
#
# In this case, the policy used is "border", which assumes all flows are
# collected on the network border interfaces, thus making ingress flows into
# that interface have a remote source address, and vice versa.
- segment: remoteaddress
  config:
    policy: "border"

###############################################################################
# Add a customer id field to all flows by CIDR match. To use it with local
# addresses, we need to run after the 'remoteaddress' segment.
- segment: addnetid
  config:
    filename: subnet_ids.csv
    dropunmatched: 1  # limit to flows belonging to customers
    useintids: 1 # user integers for customer ids

###############################################################################
# Looks up AS numbers from a local database which can be generated from
# an mrt route dump. This database can be generated using asnlookup.
- segment: aslookup
  config:
    filename: lookup.db
    type: db

###############################################################################
# Add a geolocation field to all flows. As this works on remote addresses (the
# assumption being that your own addresses are national), we need to run after
# the 'remoteaddress' segment.
- segment: geolocation
  config:
    filename: GeoLite2-Country-Test.mmdb

###############################################################################
# Add human-readable interface data for both interfaces, this specifically
# means the name, description and speed.
# The first (few) flows passing this segment will not have this information
# added, as routers are queried asynchronously. The cache will last an hour.
- segment: snmpinterface
  config:
    community: public
    # optionally supply a regex to strip down interface descriptions
    #regex: "^[a-z0-9]: (.*)$"  # strips prefix, keeps the leftmost group

###############################################################################
# Normalize Bytes and Packets using the in-flow SamplingRate or the provided
# fallback. Also sets the Normalized field to true. Does not do anything if
# neither sampling rate or fallback is non-zero.
- segment: normalize
  config:
    fallback: 32

###############################################################################
# Produce flow messages back to a Kafka topic. This can be a different one than
# above.
- segment: kafkaproducer
  config:
    server: kafka01.example.com:9093
    topic: flow-messages-enriched
    user: enricher
    pass: $KAFKA_SASL_PASS
